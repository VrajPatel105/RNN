{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is just a practice project for LSTM\n",
        "\n",
        "$$ ~Vraj Patel $$"
      ],
      "metadata": {
        "id": "u82EFQzAv6IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "faqs = \"\"\"Online Python Bootcamp FAQ\n",
        "\n",
        "Program Overview\n",
        "What is the enrollment fee for Python Bootcamp 2026?\n",
        "We charge a one-time fee of $149 for lifetime access to all materials and sessions.\n",
        "\n",
        "How long does the bootcamp last?\n",
        "The program spans 12 weeks with live coding sessions twice weekly, totaling 24 hours of instruction.\n",
        "\n",
        "What topics are covered in the curriculum?\n",
        "Core modules include:\n",
        "Python Basics and Syntax\n",
        "Data Structures & Algorithms\n",
        "File I/O and Error Handling\n",
        "Object-Oriented Programming\n",
        "Web Scraping with BeautifulSoup\n",
        "API Development with Flask\n",
        "Database Integration (SQLite/PostgreSQL)\n",
        "Testing with pytest\n",
        "Deployment on Heroku\n",
        "Real-world projects\n",
        "Detailed outline: https://pythonbootcamp.io/syllabus\n",
        "\n",
        "Does it include advanced topics like async programming?\n",
        "Yes, Weeks 9-10 cover asyncio, threading, and concurrent.futures for scalable applications.\n",
        "\n",
        "What if I miss a live coding session?\n",
        "All sessions are recorded in HD and available in your private dashboard within 2 hours.\n",
        "\n",
        "Where's the weekly schedule?\n",
        "View the live calendar here: https://calendar.google.com/bootcamp-schedule\n",
        "\n",
        "Typical session length?\n",
        "Each live session runs 90 minutes: 45 min teaching + 45 min coding challenges.\n",
        "\n",
        "Instructor language?\n",
        "English with code walkthroughs; Q&A supports multiple languages via chat.\n",
        "\n",
        "Class notifications?\n",
        "Email reminders 24 hours before each session + Discord pings for enrolled students.\n",
        "\n",
        "Suitable for complete beginners?\n",
        "Yes – starts from zero programming knowledge with daily practice assignments.\n",
        "\n",
        "Can I join after Week 1?\n",
        "Yes, catch-up materials are unlocked immediately upon enrollment.\n",
        "\n",
        "Access to previous weeks after late join?\n",
        "Full lifetime access to all 12 weeks + bonus content from day one.\n",
        "\n",
        "Assignment submission process?\n",
        "Self-paced with automated testing; solutions + video explanations provided weekly.\n",
        "\n",
        "Any capstone projects?\n",
        "Yes, final Week 12: Build and deploy a full-stack web app portfolio piece.\n",
        "\n",
        "Support contact?\n",
        "Email support@pythonbootcamp.io or Discord #help channel (24/7 moderation).\n",
        "\n",
        "Payment & Access Questions\n",
        "Where do payments process?\n",
        "Through our secure Stripe portal at pythonbootcamp.io/checkout.\n",
        "\n",
        "Can I pay in installments?\n",
        "Yes: 3 payments of $59 (paid monthly) or full $149 upfront (10% discount).\n",
        "\n",
        "Subscription renewal date?\n",
        "One-time payment = lifetime access. No recurring charges.\n",
        "\n",
        "Refund policy details?\n",
        "14-day money-back guarantee if unsatisfied after Week 1 completion.\n",
        "\n",
        "International payment issues?\n",
        "Contact support@pythonbootcamp.io – we accept PayPal, cards, and crypto.\n",
        "\n",
        "After Enrollment Queries\n",
        "Video access duration?\n",
        "Lifetime access to all recordings, updates, and new bonus content forever.\n",
        "\n",
        "Why no expiration on materials?\n",
        "Single payment model ensures long-term value for serious learners.\n",
        "\n",
        "Post-session doubt clearing?\n",
        "Weekly office hours + private Discord channels for code reviews.\n",
        "\n",
        "Late joiners: past content access?\n",
        "Everything unlocks immediately – no catch-up fees required.\n",
        "\n",
        "Payment failed internationally – next steps?\n",
        "Reply to confirmation email or Discord #billing with transaction ID.\n",
        "\n",
        "Certification & Career Support\n",
        "Certificate eligibility?\n",
        "Complete 80% of assignments + final project submission (auto-verified).\n",
        "\n",
        "Late enrollment payment for missed weeks?\n",
        "Pro-rated credits applied automatically to your dashboard.\n",
        "\n",
        "What's included in career support?\n",
        "Resume reviews (3 rounds)\n",
        "Mock technical interviews (recorded)\n",
        "LinkedIn profile optimization\n",
        "Job board access (200+ Python roles)\n",
        "Salary negotiation guides\n",
        "No job guarantees – focus on skill-building\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8TEWw0vzm4MT"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DLngbKYkkOg4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "USFbJ6HNlxXN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "1pKXDQQLmXdc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dG8se9mm9YG",
        "outputId": "d75899ba-c7c5-47a4-8470-80960effbd1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'access': 1,\n",
              " 'for': 2,\n",
              " 'and': 3,\n",
              " 'with': 4,\n",
              " 'the': 5,\n",
              " 'to': 6,\n",
              " 'payment': 7,\n",
              " 'weeks': 8,\n",
              " 'in': 9,\n",
              " 'yes': 10,\n",
              " 'session': 11,\n",
              " '–': 12,\n",
              " 'support': 13,\n",
              " 'python': 14,\n",
              " 'bootcamp': 15,\n",
              " 'enrollment': 16,\n",
              " 'a': 17,\n",
              " 'of': 18,\n",
              " 'lifetime': 19,\n",
              " 'all': 20,\n",
              " 'live': 21,\n",
              " 'weekly': 22,\n",
              " 'hours': 23,\n",
              " 'i': 24,\n",
              " 'pythonbootcamp': 25,\n",
              " 'io': 26,\n",
              " 'discord': 27,\n",
              " 'after': 28,\n",
              " 'no': 29,\n",
              " 'what': 30,\n",
              " 'one': 31,\n",
              " 'materials': 32,\n",
              " 'sessions': 33,\n",
              " '12': 34,\n",
              " 'coding': 35,\n",
              " '24': 36,\n",
              " 'are': 37,\n",
              " 'programming': 38,\n",
              " 'on': 39,\n",
              " 'email': 40,\n",
              " 'week': 41,\n",
              " 'late': 42,\n",
              " 'full': 43,\n",
              " 'content': 44,\n",
              " 'or': 45,\n",
              " 'program': 46,\n",
              " 'fee': 47,\n",
              " 'we': 48,\n",
              " 'time': 49,\n",
              " '149': 50,\n",
              " 'long': 51,\n",
              " 'does': 52,\n",
              " 'topics': 53,\n",
              " 'include': 54,\n",
              " 'web': 55,\n",
              " 'testing': 56,\n",
              " 'projects': 57,\n",
              " 'https': 58,\n",
              " '10': 59,\n",
              " 'if': 60,\n",
              " 'recorded': 61,\n",
              " 'your': 62,\n",
              " 'private': 63,\n",
              " 'dashboard': 64,\n",
              " 'schedule': 65,\n",
              " 'calendar': 66,\n",
              " 'each': 67,\n",
              " '45': 68,\n",
              " 'min': 69,\n",
              " 'code': 70,\n",
              " 'complete': 71,\n",
              " 'from': 72,\n",
              " 'assignments': 73,\n",
              " 'can': 74,\n",
              " 'join': 75,\n",
              " '1': 76,\n",
              " 'catch': 77,\n",
              " 'up': 78,\n",
              " 'immediately': 79,\n",
              " 'bonus': 80,\n",
              " 'day': 81,\n",
              " 'submission': 82,\n",
              " 'process': 83,\n",
              " 'video': 84,\n",
              " 'final': 85,\n",
              " 'contact': 86,\n",
              " 'payments': 87,\n",
              " '3': 88,\n",
              " 'reviews': 89,\n",
              " 'career': 90,\n",
              " 'job': 91,\n",
              " 'online': 92,\n",
              " 'faq': 93,\n",
              " 'overview': 94,\n",
              " 'is': 95,\n",
              " '2026': 96,\n",
              " 'charge': 97,\n",
              " 'how': 98,\n",
              " 'last': 99,\n",
              " 'spans': 100,\n",
              " 'twice': 101,\n",
              " 'totaling': 102,\n",
              " 'instruction': 103,\n",
              " 'covered': 104,\n",
              " 'curriculum': 105,\n",
              " 'core': 106,\n",
              " 'modules': 107,\n",
              " 'basics': 108,\n",
              " 'syntax': 109,\n",
              " 'data': 110,\n",
              " 'structures': 111,\n",
              " 'algorithms': 112,\n",
              " 'file': 113,\n",
              " 'o': 114,\n",
              " 'error': 115,\n",
              " 'handling': 116,\n",
              " 'object': 117,\n",
              " 'oriented': 118,\n",
              " 'scraping': 119,\n",
              " 'beautifulsoup': 120,\n",
              " 'api': 121,\n",
              " 'development': 122,\n",
              " 'flask': 123,\n",
              " 'database': 124,\n",
              " 'integration': 125,\n",
              " 'sqlite': 126,\n",
              " 'postgresql': 127,\n",
              " 'pytest': 128,\n",
              " 'deployment': 129,\n",
              " 'heroku': 130,\n",
              " 'real': 131,\n",
              " 'world': 132,\n",
              " 'detailed': 133,\n",
              " 'outline': 134,\n",
              " 'syllabus': 135,\n",
              " 'it': 136,\n",
              " 'advanced': 137,\n",
              " 'like': 138,\n",
              " 'async': 139,\n",
              " '9': 140,\n",
              " 'cover': 141,\n",
              " 'asyncio': 142,\n",
              " 'threading': 143,\n",
              " 'concurrent': 144,\n",
              " 'futures': 145,\n",
              " 'scalable': 146,\n",
              " 'applications': 147,\n",
              " 'miss': 148,\n",
              " 'hd': 149,\n",
              " 'available': 150,\n",
              " 'within': 151,\n",
              " '2': 152,\n",
              " \"where's\": 153,\n",
              " 'view': 154,\n",
              " 'here': 155,\n",
              " 'google': 156,\n",
              " 'com': 157,\n",
              " 'typical': 158,\n",
              " 'length': 159,\n",
              " 'runs': 160,\n",
              " '90': 161,\n",
              " 'minutes': 162,\n",
              " 'teaching': 163,\n",
              " 'challenges': 164,\n",
              " 'instructor': 165,\n",
              " 'language': 166,\n",
              " 'english': 167,\n",
              " 'walkthroughs': 168,\n",
              " 'q': 169,\n",
              " 'supports': 170,\n",
              " 'multiple': 171,\n",
              " 'languages': 172,\n",
              " 'via': 173,\n",
              " 'chat': 174,\n",
              " 'class': 175,\n",
              " 'notifications': 176,\n",
              " 'reminders': 177,\n",
              " 'before': 178,\n",
              " 'pings': 179,\n",
              " 'enrolled': 180,\n",
              " 'students': 181,\n",
              " 'suitable': 182,\n",
              " 'beginners': 183,\n",
              " 'starts': 184,\n",
              " 'zero': 185,\n",
              " 'knowledge': 186,\n",
              " 'daily': 187,\n",
              " 'practice': 188,\n",
              " 'unlocked': 189,\n",
              " 'upon': 190,\n",
              " 'previous': 191,\n",
              " 'assignment': 192,\n",
              " 'self': 193,\n",
              " 'paced': 194,\n",
              " 'automated': 195,\n",
              " 'solutions': 196,\n",
              " 'explanations': 197,\n",
              " 'provided': 198,\n",
              " 'any': 199,\n",
              " 'capstone': 200,\n",
              " 'build': 201,\n",
              " 'deploy': 202,\n",
              " 'stack': 203,\n",
              " 'app': 204,\n",
              " 'portfolio': 205,\n",
              " 'piece': 206,\n",
              " 'help': 207,\n",
              " 'channel': 208,\n",
              " '7': 209,\n",
              " 'moderation': 210,\n",
              " 'questions': 211,\n",
              " 'where': 212,\n",
              " 'do': 213,\n",
              " 'through': 214,\n",
              " 'our': 215,\n",
              " 'secure': 216,\n",
              " 'stripe': 217,\n",
              " 'portal': 218,\n",
              " 'at': 219,\n",
              " 'checkout': 220,\n",
              " 'pay': 221,\n",
              " 'installments': 222,\n",
              " '59': 223,\n",
              " 'paid': 224,\n",
              " 'monthly': 225,\n",
              " 'upfront': 226,\n",
              " 'discount': 227,\n",
              " 'subscription': 228,\n",
              " 'renewal': 229,\n",
              " 'date': 230,\n",
              " 'recurring': 231,\n",
              " 'charges': 232,\n",
              " 'refund': 233,\n",
              " 'policy': 234,\n",
              " 'details': 235,\n",
              " '14': 236,\n",
              " 'money': 237,\n",
              " 'back': 238,\n",
              " 'guarantee': 239,\n",
              " 'unsatisfied': 240,\n",
              " 'completion': 241,\n",
              " 'international': 242,\n",
              " 'issues': 243,\n",
              " 'accept': 244,\n",
              " 'paypal': 245,\n",
              " 'cards': 246,\n",
              " 'crypto': 247,\n",
              " 'queries': 248,\n",
              " 'duration': 249,\n",
              " 'recordings': 250,\n",
              " 'updates': 251,\n",
              " 'new': 252,\n",
              " 'forever': 253,\n",
              " 'why': 254,\n",
              " 'expiration': 255,\n",
              " 'single': 256,\n",
              " 'model': 257,\n",
              " 'ensures': 258,\n",
              " 'term': 259,\n",
              " 'value': 260,\n",
              " 'serious': 261,\n",
              " 'learners': 262,\n",
              " 'post': 263,\n",
              " 'doubt': 264,\n",
              " 'clearing': 265,\n",
              " 'office': 266,\n",
              " 'channels': 267,\n",
              " 'joiners': 268,\n",
              " 'past': 269,\n",
              " 'everything': 270,\n",
              " 'unlocks': 271,\n",
              " 'fees': 272,\n",
              " 'required': 273,\n",
              " 'failed': 274,\n",
              " 'internationally': 275,\n",
              " 'next': 276,\n",
              " 'steps': 277,\n",
              " 'reply': 278,\n",
              " 'confirmation': 279,\n",
              " 'billing': 280,\n",
              " 'transaction': 281,\n",
              " 'id': 282,\n",
              " 'certification': 283,\n",
              " 'certificate': 284,\n",
              " 'eligibility': 285,\n",
              " '80': 286,\n",
              " 'project': 287,\n",
              " 'auto': 288,\n",
              " 'verified': 289,\n",
              " 'missed': 290,\n",
              " 'pro': 291,\n",
              " 'rated': 292,\n",
              " 'credits': 293,\n",
              " 'applied': 294,\n",
              " 'automatically': 295,\n",
              " \"what's\": 296,\n",
              " 'included': 297,\n",
              " 'resume': 298,\n",
              " 'rounds': 299,\n",
              " 'mock': 300,\n",
              " 'technical': 301,\n",
              " 'interviews': 302,\n",
              " 'linkedin': 303,\n",
              " 'profile': 304,\n",
              " 'optimization': 305,\n",
              " 'board': 306,\n",
              " '200': 307,\n",
              " 'roles': 308,\n",
              " 'salary': 309,\n",
              " 'negotiation': 310,\n",
              " 'guides': 311,\n",
              " 'guarantees': 312,\n",
              " 'focus': 313,\n",
              " 'skill': 314,\n",
              " 'building': 315}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "2lie1BQNm_px"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have simply converted our entire data (faqs) into numbers"
      ],
      "metadata": {
        "id": "yP-FR2uSnsA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlFxxoelpy_O",
        "outputId": "682465a4-8c66-4d4f-d798-72497f1c5624"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[92, 14],\n",
              " [92, 14, 15],\n",
              " [92, 14, 15, 93],\n",
              " [46, 94],\n",
              " [30, 95],\n",
              " [30, 95, 5],\n",
              " [30, 95, 5, 16],\n",
              " [30, 95, 5, 16, 47],\n",
              " [30, 95, 5, 16, 47, 2],\n",
              " [30, 95, 5, 16, 47, 2, 14],\n",
              " [30, 95, 5, 16, 47, 2, 14, 15],\n",
              " [30, 95, 5, 16, 47, 2, 14, 15, 96],\n",
              " [48, 97],\n",
              " [48, 97, 17],\n",
              " [48, 97, 17, 31],\n",
              " [48, 97, 17, 31, 49],\n",
              " [48, 97, 17, 31, 49, 47],\n",
              " [48, 97, 17, 31, 49, 47, 18],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1, 6],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1, 6, 20],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1, 6, 20, 32],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1, 6, 20, 32, 3],\n",
              " [48, 97, 17, 31, 49, 47, 18, 50, 2, 19, 1, 6, 20, 32, 3, 33],\n",
              " [98, 51],\n",
              " [98, 51, 52],\n",
              " [98, 51, 52, 5],\n",
              " [98, 51, 52, 5, 15],\n",
              " [98, 51, 52, 5, 15, 99],\n",
              " [5, 46],\n",
              " [5, 46, 100],\n",
              " [5, 46, 100, 34],\n",
              " [5, 46, 100, 34, 8],\n",
              " [5, 46, 100, 34, 8, 4],\n",
              " [5, 46, 100, 34, 8, 4, 21],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22, 102],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22, 102, 36],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22, 102, 36, 23],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22, 102, 36, 23, 18],\n",
              " [5, 46, 100, 34, 8, 4, 21, 35, 33, 101, 22, 102, 36, 23, 18, 103],\n",
              " [30, 53],\n",
              " [30, 53, 37],\n",
              " [30, 53, 37, 104],\n",
              " [30, 53, 37, 104, 9],\n",
              " [30, 53, 37, 104, 9, 5],\n",
              " [30, 53, 37, 104, 9, 5, 105],\n",
              " [106, 107],\n",
              " [106, 107, 54],\n",
              " [14, 108],\n",
              " [14, 108, 3],\n",
              " [14, 108, 3, 109],\n",
              " [110, 111],\n",
              " [110, 111, 112],\n",
              " [113, 24],\n",
              " [113, 24, 114],\n",
              " [113, 24, 114, 3],\n",
              " [113, 24, 114, 3, 115],\n",
              " [113, 24, 114, 3, 115, 116],\n",
              " [117, 118],\n",
              " [117, 118, 38],\n",
              " [55, 119],\n",
              " [55, 119, 4],\n",
              " [55, 119, 4, 120],\n",
              " [121, 122],\n",
              " [121, 122, 4],\n",
              " [121, 122, 4, 123],\n",
              " [124, 125],\n",
              " [124, 125, 126],\n",
              " [124, 125, 126, 127],\n",
              " [56, 4],\n",
              " [56, 4, 128],\n",
              " [129, 39],\n",
              " [129, 39, 130],\n",
              " [131, 132],\n",
              " [131, 132, 57],\n",
              " [133, 134],\n",
              " [133, 134, 58],\n",
              " [133, 134, 58, 25],\n",
              " [133, 134, 58, 25, 26],\n",
              " [133, 134, 58, 25, 26, 135],\n",
              " [52, 136],\n",
              " [52, 136, 54],\n",
              " [52, 136, 54, 137],\n",
              " [52, 136, 54, 137, 53],\n",
              " [52, 136, 54, 137, 53, 138],\n",
              " [52, 136, 54, 137, 53, 138, 139],\n",
              " [52, 136, 54, 137, 53, 138, 139, 38],\n",
              " [10, 8],\n",
              " [10, 8, 140],\n",
              " [10, 8, 140, 59],\n",
              " [10, 8, 140, 59, 141],\n",
              " [10, 8, 140, 59, 141, 142],\n",
              " [10, 8, 140, 59, 141, 142, 143],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3, 144],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3, 144, 145],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3, 144, 145, 2],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3, 144, 145, 2, 146],\n",
              " [10, 8, 140, 59, 141, 142, 143, 3, 144, 145, 2, 146, 147],\n",
              " [30, 60],\n",
              " [30, 60, 24],\n",
              " [30, 60, 24, 148],\n",
              " [30, 60, 24, 148, 17],\n",
              " [30, 60, 24, 148, 17, 21],\n",
              " [30, 60, 24, 148, 17, 21, 35],\n",
              " [30, 60, 24, 148, 17, 21, 35, 11],\n",
              " [20, 33],\n",
              " [20, 33, 37],\n",
              " [20, 33, 37, 61],\n",
              " [20, 33, 37, 61, 9],\n",
              " [20, 33, 37, 61, 9, 149],\n",
              " [20, 33, 37, 61, 9, 149, 3],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62, 63],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62, 63, 64],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62, 63, 64, 151],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62, 63, 64, 151, 152],\n",
              " [20, 33, 37, 61, 9, 149, 3, 150, 9, 62, 63, 64, 151, 152, 23],\n",
              " [153, 5],\n",
              " [153, 5, 22],\n",
              " [153, 5, 22, 65],\n",
              " [154, 5],\n",
              " [154, 5, 21],\n",
              " [154, 5, 21, 66],\n",
              " [154, 5, 21, 66, 155],\n",
              " [154, 5, 21, 66, 155, 58],\n",
              " [154, 5, 21, 66, 155, 58, 66],\n",
              " [154, 5, 21, 66, 155, 58, 66, 156],\n",
              " [154, 5, 21, 66, 155, 58, 66, 156, 157],\n",
              " [154, 5, 21, 66, 155, 58, 66, 156, 157, 15],\n",
              " [154, 5, 21, 66, 155, 58, 66, 156, 157, 15, 65],\n",
              " [158, 11],\n",
              " [158, 11, 159],\n",
              " [67, 21],\n",
              " [67, 21, 11],\n",
              " [67, 21, 11, 160],\n",
              " [67, 21, 11, 160, 161],\n",
              " [67, 21, 11, 160, 161, 162],\n",
              " [67, 21, 11, 160, 161, 162, 68],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69, 163],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69, 163, 68],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69, 163, 68, 69],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69, 163, 68, 69, 35],\n",
              " [67, 21, 11, 160, 161, 162, 68, 69, 163, 68, 69, 35, 164],\n",
              " [165, 166],\n",
              " [167, 4],\n",
              " [167, 4, 70],\n",
              " [167, 4, 70, 168],\n",
              " [167, 4, 70, 168, 169],\n",
              " [167, 4, 70, 168, 169, 17],\n",
              " [167, 4, 70, 168, 169, 17, 170],\n",
              " [167, 4, 70, 168, 169, 17, 170, 171],\n",
              " [167, 4, 70, 168, 169, 17, 170, 171, 172],\n",
              " [167, 4, 70, 168, 169, 17, 170, 171, 172, 173],\n",
              " [167, 4, 70, 168, 169, 17, 170, 171, 172, 173, 174],\n",
              " [175, 176],\n",
              " [40, 177],\n",
              " [40, 177, 36],\n",
              " [40, 177, 36, 23],\n",
              " [40, 177, 36, 23, 178],\n",
              " [40, 177, 36, 23, 178, 67],\n",
              " [40, 177, 36, 23, 178, 67, 11],\n",
              " [40, 177, 36, 23, 178, 67, 11, 27],\n",
              " [40, 177, 36, 23, 178, 67, 11, 27, 179],\n",
              " [40, 177, 36, 23, 178, 67, 11, 27, 179, 2],\n",
              " [40, 177, 36, 23, 178, 67, 11, 27, 179, 2, 180],\n",
              " [40, 177, 36, 23, 178, 67, 11, 27, 179, 2, 180, 181],\n",
              " [182, 2],\n",
              " [182, 2, 71],\n",
              " [182, 2, 71, 183],\n",
              " [10, 12],\n",
              " [10, 12, 184],\n",
              " [10, 12, 184, 72],\n",
              " [10, 12, 184, 72, 185],\n",
              " [10, 12, 184, 72, 185, 38],\n",
              " [10, 12, 184, 72, 185, 38, 186],\n",
              " [10, 12, 184, 72, 185, 38, 186, 4],\n",
              " [10, 12, 184, 72, 185, 38, 186, 4, 187],\n",
              " [10, 12, 184, 72, 185, 38, 186, 4, 187, 188],\n",
              " [10, 12, 184, 72, 185, 38, 186, 4, 187, 188, 73],\n",
              " [74, 24],\n",
              " [74, 24, 75],\n",
              " [74, 24, 75, 28],\n",
              " [74, 24, 75, 28, 41],\n",
              " [74, 24, 75, 28, 41, 76],\n",
              " [10, 77],\n",
              " [10, 77, 78],\n",
              " [10, 77, 78, 32],\n",
              " [10, 77, 78, 32, 37],\n",
              " [10, 77, 78, 32, 37, 189],\n",
              " [10, 77, 78, 32, 37, 189, 79],\n",
              " [10, 77, 78, 32, 37, 189, 79, 190],\n",
              " [10, 77, 78, 32, 37, 189, 79, 190, 16],\n",
              " [1, 6],\n",
              " [1, 6, 191],\n",
              " [1, 6, 191, 8],\n",
              " [1, 6, 191, 8, 28],\n",
              " [1, 6, 191, 8, 28, 42],\n",
              " [1, 6, 191, 8, 28, 42, 75],\n",
              " [43, 19],\n",
              " [43, 19, 1],\n",
              " [43, 19, 1, 6],\n",
              " [43, 19, 1, 6, 20],\n",
              " [43, 19, 1, 6, 20, 34],\n",
              " [43, 19, 1, 6, 20, 34, 8],\n",
              " [43, 19, 1, 6, 20, 34, 8, 80],\n",
              " [43, 19, 1, 6, 20, 34, 8, 80, 44],\n",
              " [43, 19, 1, 6, 20, 34, 8, 80, 44, 72],\n",
              " [43, 19, 1, 6, 20, 34, 8, 80, 44, 72, 81],\n",
              " [43, 19, 1, 6, 20, 34, 8, 80, 44, 72, 81, 31],\n",
              " [192, 82],\n",
              " [192, 82, 83],\n",
              " [193, 194],\n",
              " [193, 194, 4],\n",
              " [193, 194, 4, 195],\n",
              " [193, 194, 4, 195, 56],\n",
              " [193, 194, 4, 195, 56, 196],\n",
              " [193, 194, 4, 195, 56, 196, 84],\n",
              " [193, 194, 4, 195, 56, 196, 84, 197],\n",
              " [193, 194, 4, 195, 56, 196, 84, 197, 198],\n",
              " [193, 194, 4, 195, 56, 196, 84, 197, 198, 22],\n",
              " [199, 200],\n",
              " [199, 200, 57],\n",
              " [10, 85],\n",
              " [10, 85, 41],\n",
              " [10, 85, 41, 34],\n",
              " [10, 85, 41, 34, 201],\n",
              " [10, 85, 41, 34, 201, 3],\n",
              " [10, 85, 41, 34, 201, 3, 202],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43, 203],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43, 203, 55],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43, 203, 55, 204],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43, 203, 55, 204, 205],\n",
              " [10, 85, 41, 34, 201, 3, 202, 17, 43, 203, 55, 204, 205, 206],\n",
              " [13, 86],\n",
              " [40, 13],\n",
              " [40, 13, 25],\n",
              " [40, 13, 25, 26],\n",
              " [40, 13, 25, 26, 45],\n",
              " [40, 13, 25, 26, 45, 27],\n",
              " [40, 13, 25, 26, 45, 27, 207],\n",
              " [40, 13, 25, 26, 45, 27, 207, 208],\n",
              " [40, 13, 25, 26, 45, 27, 207, 208, 36],\n",
              " [40, 13, 25, 26, 45, 27, 207, 208, 36, 209],\n",
              " [40, 13, 25, 26, 45, 27, 207, 208, 36, 209, 210],\n",
              " [7, 1],\n",
              " [7, 1, 211],\n",
              " [212, 213],\n",
              " [212, 213, 87],\n",
              " [212, 213, 87, 83],\n",
              " [214, 215],\n",
              " [214, 215, 216],\n",
              " [214, 215, 216, 217],\n",
              " [214, 215, 216, 217, 218],\n",
              " [214, 215, 216, 217, 218, 219],\n",
              " [214, 215, 216, 217, 218, 219, 25],\n",
              " [214, 215, 216, 217, 218, 219, 25, 26],\n",
              " [214, 215, 216, 217, 218, 219, 25, 26, 220],\n",
              " [74, 24],\n",
              " [74, 24, 221],\n",
              " [74, 24, 221, 9],\n",
              " [74, 24, 221, 9, 222],\n",
              " [10, 88],\n",
              " [10, 88, 87],\n",
              " [10, 88, 87, 18],\n",
              " [10, 88, 87, 18, 223],\n",
              " [10, 88, 87, 18, 223, 224],\n",
              " [10, 88, 87, 18, 223, 224, 225],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45, 43],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45, 43, 50],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45, 43, 50, 226],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45, 43, 50, 226, 59],\n",
              " [10, 88, 87, 18, 223, 224, 225, 45, 43, 50, 226, 59, 227],\n",
              " [228, 229],\n",
              " [228, 229, 230],\n",
              " [31, 49],\n",
              " [31, 49, 7],\n",
              " [31, 49, 7, 19],\n",
              " [31, 49, 7, 19, 1],\n",
              " [31, 49, 7, 19, 1, 29],\n",
              " [31, 49, 7, 19, 1, 29, 231],\n",
              " [31, 49, 7, 19, 1, 29, 231, 232],\n",
              " [233, 234],\n",
              " [233, 234, 235],\n",
              " [236, 81],\n",
              " [236, 81, 237],\n",
              " [236, 81, 237, 238],\n",
              " [236, 81, 237, 238, 239],\n",
              " [236, 81, 237, 238, 239, 60],\n",
              " [236, 81, 237, 238, 239, 60, 240],\n",
              " [236, 81, 237, 238, 239, 60, 240, 28],\n",
              " [236, 81, 237, 238, 239, 60, 240, 28, 41],\n",
              " [236, 81, 237, 238, 239, 60, 240, 28, 41, 76],\n",
              " [236, 81, 237, 238, 239, 60, 240, 28, 41, 76, 241],\n",
              " [242, 7],\n",
              " [242, 7, 243],\n",
              " [86, 13],\n",
              " [86, 13, 25],\n",
              " [86, 13, 25, 26],\n",
              " [86, 13, 25, 26, 12],\n",
              " [86, 13, 25, 26, 12, 48],\n",
              " [86, 13, 25, 26, 12, 48, 244],\n",
              " [86, 13, 25, 26, 12, 48, 244, 245],\n",
              " [86, 13, 25, 26, 12, 48, 244, 245, 246],\n",
              " [86, 13, 25, 26, 12, 48, 244, 245, 246, 3],\n",
              " [86, 13, 25, 26, 12, 48, 244, 245, 246, 3, 247],\n",
              " [28, 16],\n",
              " [28, 16, 248],\n",
              " [84, 1],\n",
              " [84, 1, 249],\n",
              " [19, 1],\n",
              " [19, 1, 6],\n",
              " [19, 1, 6, 20],\n",
              " [19, 1, 6, 20, 250],\n",
              " [19, 1, 6, 20, 250, 251],\n",
              " [19, 1, 6, 20, 250, 251, 3],\n",
              " [19, 1, 6, 20, 250, 251, 3, 252],\n",
              " [19, 1, 6, 20, 250, 251, 3, 252, 80],\n",
              " [19, 1, 6, 20, 250, 251, 3, 252, 80, 44],\n",
              " [19, 1, 6, 20, 250, 251, 3, 252, 80, 44, 253],\n",
              " [254, 29],\n",
              " [254, 29, 255],\n",
              " [254, 29, 255, 39],\n",
              " [254, 29, 255, 39, 32],\n",
              " [256, 7],\n",
              " [256, 7, 257],\n",
              " [256, 7, 257, 258],\n",
              " [256, 7, 257, 258, 51],\n",
              " [256, 7, 257, 258, 51, 259],\n",
              " [256, 7, 257, 258, 51, 259, 260],\n",
              " [256, 7, 257, 258, 51, 259, 260, 2],\n",
              " [256, 7, 257, 258, 51, 259, 260, 2, 261],\n",
              " [256, 7, 257, 258, 51, 259, 260, 2, 261, 262],\n",
              " [263, 11],\n",
              " [263, 11, 264],\n",
              " [263, 11, 264, 265],\n",
              " [22, 266],\n",
              " [22, 266, 23],\n",
              " [22, 266, 23, 63],\n",
              " [22, 266, 23, 63, 27],\n",
              " [22, 266, 23, 63, 27, 267],\n",
              " [22, 266, 23, 63, 27, 267, 2],\n",
              " [22, 266, 23, 63, 27, 267, 2, 70],\n",
              " [22, 266, 23, 63, 27, 267, 2, 70, 89],\n",
              " [42, 268],\n",
              " [42, 268, 269],\n",
              " [42, 268, 269, 44],\n",
              " [42, 268, 269, 44, 1],\n",
              " [270, 271],\n",
              " [270, 271, 79],\n",
              " [270, 271, 79, 12],\n",
              " [270, 271, 79, 12, 29],\n",
              " [270, 271, 79, 12, 29, 77],\n",
              " [270, 271, 79, 12, 29, 77, 78],\n",
              " [270, 271, 79, 12, 29, 77, 78, 272],\n",
              " [270, 271, 79, 12, 29, 77, 78, 272, 273],\n",
              " [7, 274],\n",
              " [7, 274, 275],\n",
              " [7, 274, 275, 12],\n",
              " [7, 274, 275, 12, 276],\n",
              " [7, 274, 275, 12, 276, 277],\n",
              " [278, 6],\n",
              " [278, 6, 279],\n",
              " [278, 6, 279, 40],\n",
              " [278, 6, 279, 40, 45],\n",
              " [278, 6, 279, 40, 45, 27],\n",
              " [278, 6, 279, 40, 45, 27, 280],\n",
              " [278, 6, 279, 40, 45, 27, 280, 4],\n",
              " [278, 6, 279, 40, 45, 27, 280, 4, 281],\n",
              " [278, 6, 279, 40, 45, 27, 280, 4, 281, 282],\n",
              " [283, 90],\n",
              " [283, 90, 13],\n",
              " [284, 285],\n",
              " [71, 286],\n",
              " [71, 286, 18],\n",
              " [71, 286, 18, 73],\n",
              " [71, 286, 18, 73, 85],\n",
              " [71, 286, 18, 73, 85, 287],\n",
              " [71, 286, 18, 73, 85, 287, 82],\n",
              " [71, 286, 18, 73, 85, 287, 82, 288],\n",
              " [71, 286, 18, 73, 85, 287, 82, 288, 289],\n",
              " [42, 16],\n",
              " [42, 16, 7],\n",
              " [42, 16, 7, 2],\n",
              " [42, 16, 7, 2, 290],\n",
              " [42, 16, 7, 2, 290, 8],\n",
              " [291, 292],\n",
              " [291, 292, 293],\n",
              " [291, 292, 293, 294],\n",
              " [291, 292, 293, 294, 295],\n",
              " [291, 292, 293, 294, 295, 6],\n",
              " [291, 292, 293, 294, 295, 6, 62],\n",
              " [291, 292, 293, 294, 295, 6, 62, 64],\n",
              " [296, 297],\n",
              " [296, 297, 9],\n",
              " [296, 297, 9, 90],\n",
              " [296, 297, 9, 90, 13],\n",
              " [298, 89],\n",
              " [298, 89, 88],\n",
              " [298, 89, 88, 299],\n",
              " [300, 301],\n",
              " [300, 301, 302],\n",
              " [300, 301, 302, 61],\n",
              " [303, 304],\n",
              " [303, 304, 305],\n",
              " [91, 306],\n",
              " [91, 306, 1],\n",
              " [91, 306, 1, 307],\n",
              " [91, 306, 1, 307, 14],\n",
              " [91, 306, 1, 307, 14, 308],\n",
              " [309, 310],\n",
              " [309, 310, 311],\n",
              " [29, 91],\n",
              " [29, 91, 312],\n",
              " [29, 91, 312, 12],\n",
              " [29, 91, 312, 12, 313],\n",
              " [29, 91, 312, 12, 313, 39],\n",
              " [29, 91, 312, 12, 313, 39, 314],\n",
              " [29, 91, 312, 12, 313, 39, 314, 315]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# since the size of all these lists above is not the same, we will apply zero padding\n",
        "# for applying zero padding, we will just identify the length of the sentence with max length\n",
        "max_len = max([len(x) for x in input_sequences])"
      ],
      "metadata": {
        "id": "1zZmIE86oGzw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4zDr7fXtiSz",
        "outputId": "7cbac4dd-ba11-45ec-af5c-cac52fecc56b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "a4GuVkTPqBgU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences = pad_sequences(input_sequences, maxlen = max_len, padding='pre')"
      ],
      "metadata": {
        "id": "QOF_sxKaqFfR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M04Qh9SGqKzx",
        "outputId": "80e1857e-5d9d-4e18-f78c-cb1a8ca5488b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 92, 14],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the last element in all these list (padded_input_sequences) will be the output\n",
        "X = padded_input_sequences[:,:-1]\n",
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "LOxt7AeLqMbJ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tseohxeqaIb",
        "outputId": "ec7628f1-25e8-4837-cced-24d912540e87"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr_4YDUzqbKU",
        "outputId": "632248d3-2108-4638-9ca9-4c12078f1716"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432,)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fQHy-b7sNJ2",
        "outputId": "132ae2a9-99c0-4ef9-dcce-f1493217a4aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "315"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will consider this as a multiclass classification problem\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=316)"
      ],
      "metadata": {
        "id": "ZpJILxcpqbjE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmBXd5uAsRHp",
        "outputId": "0208bbbd-f998-4037-b4c8-d1a3c45384e3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432, 316)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[213] # we just use OHE on output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOIA1AKZskie",
        "outputId": "a93774b5-26dc-4b5f-e865-0dd4a32c2692"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "TBE-sqeCsnIF"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(316, 100, input_length=max_len, input_shape=(max_len,)))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(316, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9gUnyb_tNU0",
        "outputId": "80947d51-1b59-46ca-fef5-3f355b6c6410"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ot5dczLztteE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "et1Cv0BKt07Y",
        "outputId": "24465fad-03e5-4a30-f6fa-08e074f97394"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m31,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m80,400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m316\u001b[0m)            │        \u001b[38;5;34m31,916\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">316</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,916</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,916\u001b[0m (562.17 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,916</span> (562.17 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,916\u001b[0m (562.17 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,916</span> (562.17 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CjGR6Knst2HX"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFUCALCfJRR",
        "outputId": "1e4cbffe-ee95-49e0-8f50-3d47de0f94ae"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.0026 - loss: 5.7553\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0219 - loss: 5.7155\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0044 - loss: 5.5600\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0146 - loss: 5.4728\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0185 - loss: 5.4021\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0250 - loss: 5.3609\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0282 - loss: 5.2276\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0303 - loss: 5.2112\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0276 - loss: 5.1078\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0413 - loss: 5.1363\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0490 - loss: 4.9779\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0329 - loss: 4.9177\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0668 - loss: 4.8100\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0790 - loss: 4.5995\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0826 - loss: 4.5829\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1055 - loss: 4.4429\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1062 - loss: 4.3010\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1611 - loss: 4.1543\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1523 - loss: 4.1182\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1651 - loss: 4.0024\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2123 - loss: 3.8632\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2155 - loss: 3.7316\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2464 - loss: 3.6370\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.2749 - loss: 3.4955\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2897 - loss: 3.4776\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3417 - loss: 3.1853\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3566 - loss: 3.1103\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4046 - loss: 3.0464\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4558 - loss: 2.9378\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4220 - loss: 2.8393\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4782 - loss: 2.7530\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4929 - loss: 2.6484\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5194 - loss: 2.5383\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5354 - loss: 2.4453\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5623 - loss: 2.3954\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5930 - loss: 2.2662\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6040 - loss: 2.1903\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6449 - loss: 2.0691\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6876 - loss: 1.9841\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 1.8949\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7081 - loss: 1.8709\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 1.7996\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7723 - loss: 1.6679\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7664 - loss: 1.6736\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8170 - loss: 1.5854\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 1.5344\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8505 - loss: 1.5023\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8610 - loss: 1.3882\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 1.3546\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8757 - loss: 1.3297\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9128 - loss: 1.2483\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9175 - loss: 1.1736\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 1.1040\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9068 - loss: 1.1316\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9286 - loss: 1.0571\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9336 - loss: 0.9775\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9364 - loss: 0.9603\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9462 - loss: 0.9597\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.8978\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9521 - loss: 0.8462\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9620 - loss: 0.8354\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9727 - loss: 0.7948\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9647 - loss: 0.7606\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.7409\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9524 - loss: 0.7264\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9607 - loss: 0.6835\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9673 - loss: 0.6617\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9793 - loss: 0.6072\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.5803\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9694 - loss: 0.5886\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9797 - loss: 0.5432\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9757 - loss: 0.5167\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9726 - loss: 0.5171\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.4793\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9750 - loss: 0.4912\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9788 - loss: 0.4434\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9744 - loss: 0.4323\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.4415\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9788 - loss: 0.4059\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9782 - loss: 0.3892\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.3766\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.3659\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9754 - loss: 0.3732\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9692 - loss: 0.3789\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9705 - loss: 0.3469\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9781 - loss: 0.3259\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.3092\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9770 - loss: 0.3013\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9763 - loss: 0.2974\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9751 - loss: 0.2999\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9692 - loss: 0.2815\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9775 - loss: 0.2684\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.2635\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9672 - loss: 0.2939\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.2557\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.2387\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9828 - loss: 0.2215\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9724 - loss: 0.2510\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9740 - loss: 0.2430\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9814 - loss: 0.2221\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a089b6f78c0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "text = \"What is the enrollment\"\n",
        "\n",
        "for i in range(10):\n",
        "  # tokenize\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "  # padding\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "  # predict\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA3hnNcevdd6",
        "outputId": "d92117f9-ff8c-47f6-f0fa-60962c2e5f89"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
            "What is the enrollment fee\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "What is the enrollment fee for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "What is the enrollment fee for fee\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "What is the enrollment fee for fee for\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "What is the enrollment fee for fee for python\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "What is the enrollment fee for fee for python bootcamp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "What is the enrollment fee for fee for python bootcamp faq\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "What is the enrollment fee for fee for python bootcamp faq python\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "What is the enrollment fee for fee for python bootcamp faq python bootcamp\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "What is the enrollment fee for fee for python bootcamp faq python bootcamp 2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T1ki9DBjvvH8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}